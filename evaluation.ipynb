{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6d7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontology_generation.Evaluation import Evaluation\n",
    "from ontology_generation.OntologyGen import OntologyGen\n",
    "from ontology_generation.OntologyEncap import OntologyEncap\n",
    "import re\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from rdflib import Namespace, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2466d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontogen = OntologyGen(model_name=\"gpt-4-1106-preview\", deployment_name=\"gpt_chat_test_preview\")\n",
    "topic_name = \"natural language processing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee684cf",
   "metadata": {},
   "source": [
    "#### CSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa5674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "file_path = \"data/CSO.3.3.ttl\"\n",
    "parent_topic_uri = \"https://cso.kmi.open.ac.uk/topics/natural_language_processing\"\n",
    "deduplicated_topics = Evaluation.extract_concepts_and_deduplicate(file_path, parent_topic_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec14e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts in CSO:  168\n"
     ]
    }
   ],
   "source": [
    "cso_concepts = Evaluation.clean_concept_names(deduplicated_topics)\n",
    "print(\"Number of concepts in CSO: \", len(cso_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91feee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['word embeddings',\n",
       " 'translation quality',\n",
       " 'web information extraction',\n",
       " 'synsets',\n",
       " 'text processing',\n",
       " 'n-gram language models',\n",
       " 'information extraction systems',\n",
       " 'text clustering',\n",
       " 'computational grammars',\n",
       " 'semantic distance',\n",
       " 'textual entailment',\n",
       " 'word segmentation',\n",
       " 'treebanks',\n",
       " 'text feature',\n",
       " 'information extraction techniques',\n",
       " 'unit selection',\n",
       " 'grammatical inferences',\n",
       " 'information retrieval technology',\n",
       " 'translation process',\n",
       " 'translation systems',\n",
       " 'cross language information retrieval',\n",
       " 'computing with words',\n",
       " 'part-of-speech tagging',\n",
       " 'dialogue manager',\n",
       " 'text representation',\n",
       " 'text data',\n",
       " 'text categorization',\n",
       " 'product reviews',\n",
       " 'free texts',\n",
       " 'sentiment analysis',\n",
       " 'sequence labeling',\n",
       " 'bilingual corpora',\n",
       " 'dependency parsing',\n",
       " 'text classification methods',\n",
       " 'electronic document',\n",
       " 'source language',\n",
       " 'topic model',\n",
       " 'word processing',\n",
       " 'pos tagging',\n",
       " 'natural language generation',\n",
       " 'inverse document frequency',\n",
       " 'sentiment classification',\n",
       " 'style sheets',\n",
       " 'online products',\n",
       " 'parsing algorithm',\n",
       " 'bilingual dictionary',\n",
       " 'query translation',\n",
       " 'text mining techniques',\n",
       " 'machine translation',\n",
       " 'pos taggers',\n",
       " 'word sense disambiguation',\n",
       " 'text recognition',\n",
       " 'lexical database',\n",
       " 'text classification',\n",
       " 'automatic evaluation',\n",
       " 'document classification',\n",
       " 'parallel text',\n",
       " 'text entry',\n",
       " 'smt systems',\n",
       " 'dom tree',\n",
       " 'word sense',\n",
       " 'statistical machine translation system',\n",
       " 'syntactic information',\n",
       " 'hierarchical dirichlet process',\n",
       " 'term frequency',\n",
       " 'text classifiers',\n",
       " 'reuters-21578',\n",
       " 'term weighting',\n",
       " 'word alignment',\n",
       " 'maximum entropy models',\n",
       " 'subject headings',\n",
       " 'textual data',\n",
       " 'training documents',\n",
       " 'spoken dialogue systems',\n",
       " 'human evaluation',\n",
       " 'telluric prospecting',\n",
       " 'text localization',\n",
       " 'speech-to-speech translation',\n",
       " 'semantic similarity measures',\n",
       " 'natural scene images',\n",
       " 'relevance models',\n",
       " 'sentence extraction',\n",
       " 'named entities',\n",
       " 'text mining',\n",
       " 'lexical semantics',\n",
       " 'speech transmission',\n",
       " 'dependency trees',\n",
       " 'scene text',\n",
       " 'parsing',\n",
       " 'text detection',\n",
       " 'text document',\n",
       " 'document categorization',\n",
       " 'grammatical evolution',\n",
       " 'syntactic parsing',\n",
       " 'semantic orientation',\n",
       " 'document frequency',\n",
       " 'customer review',\n",
       " 'opinion mining',\n",
       " 'statistical language models',\n",
       " 'automatic translation',\n",
       " 'named entity',\n",
       " 'abstracting and indexing',\n",
       " 'phrase-based statistical machine translation',\n",
       " 'semantic similarity',\n",
       " 'dependency parser',\n",
       " 'syntactic structure',\n",
       " 'speech translation',\n",
       " 'error rate %28er%29',\n",
       " 'question answering systems',\n",
       " 'spoken language processing',\n",
       " 'lexical resources',\n",
       " 'parse trees',\n",
       " 'wordnet',\n",
       " 'english sentences',\n",
       " 'automatic summarization',\n",
       " 'text region',\n",
       " 'statistical machine translation',\n",
       " 'statistical language modeling',\n",
       " 'name recognition',\n",
       " 'word similarity',\n",
       " 'natural language questions',\n",
       " 'dialogue management',\n",
       " 'n-gram models',\n",
       " 'grammar induction',\n",
       " 'parallel corpora',\n",
       " 'concept similarity',\n",
       " 'question classification',\n",
       " 'polarity classification',\n",
       " 'text lines',\n",
       " 'speech transcriptions',\n",
       " 'text summarization',\n",
       " 'computer aided language translation',\n",
       " 'spoken language understanding',\n",
       " 'relation extraction',\n",
       " 'natural language text',\n",
       " 'syntactic analysis',\n",
       " 'qa system',\n",
       " 'syntactic features',\n",
       " 'pseudo relevance feedback',\n",
       " 'translation models',\n",
       " 'data abstraction',\n",
       " 'document representation',\n",
       " 'text input',\n",
       " 'extracting information',\n",
       " 'answer extraction',\n",
       " 'target language',\n",
       " 'information extraction',\n",
       " 'formal grammars',\n",
       " 'complex questions',\n",
       " 'product feature',\n",
       " 'language pairs',\n",
       " 'chinese word segmentation',\n",
       " 'spoken dialogue',\n",
       " 'natural language understanding',\n",
       " 'passage retrieval',\n",
       " 'automatic text summarization',\n",
       " 'sentence similarity',\n",
       " 'computing with word %28cww%29',\n",
       " 'part of speech tagging']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function to normalize topics\n",
    "def normalize_topic(topic):\n",
    "    # Convert to lowercase and replace hyphens with underscores\n",
    "    topic = topic.lower().replace(\"-\", \"_\")\n",
    "    # Remove trailing 's' for plurals\n",
    "    topic = re.sub(r's$', '', topic)\n",
    "    # Remove parentheses and their contents\n",
    "    topic = re.sub(r'\\([^)]*\\)', '', topic)\n",
    "    # Remove any remaining special characters and extra whitespace\n",
    "    topic = re.sub(r'[^a-z0-9_]', '', topic)\n",
    "    return topic\n",
    "\n",
    "# Function to check if two topics are similar based on a threshold\n",
    "def are_similar(a, b, threshold=0.95):\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold\n",
    "\n",
    "# Set for normalized topics to track seen ones\n",
    "seen = set()\n",
    "# List to store unique topics\n",
    "unique_topics = []\n",
    "\n",
    "# First pass: Remove exact duplicates using normalization\n",
    "for topic in cso_concepts:\n",
    "    normalized = normalize_topic(topic)\n",
    "    if normalized not in seen:\n",
    "        seen.add(normalized)\n",
    "        unique_topics.append(topic)\n",
    "\n",
    "# Second pass: Check for similar topics using SequenceMatcher\n",
    "final_topics = []\n",
    "for topic in unique_topics:\n",
    "    if not any(are_similar(normalize_topic(topic), normalize_topic(existing)) for existing in final_topics):\n",
    "        final_topics.append(topic)\n",
    "\n",
    "# Print the number of unique topics and the topics themselves\n",
    "print(len(final_topics))\n",
    "final_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32fbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role = \"You are an ontology engineer\"\n",
    "# prompt = f'''You are a model tasked with deleting duplicate topics from a list for ontology creation for the {topic_name} domain. \n",
    "# The list: ''' + ', '.join(unique_topics) + '''\n",
    "# Return the response only in the dictionary format. Do not add new topics. Ensure proper use of quotations:\n",
    "# {\n",
    "# 'topic1',\n",
    "# 'topic2\n",
    "# }\n",
    "# '''\n",
    "# cso_list = ontogen.prompt_extract(role, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6527be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of concepts in CSO: \", len(cso_list))\n",
    "# cso_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641daceb",
   "metadata": {},
   "source": [
    "#### AutOnto with OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0a2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept_uri = \"http://fraunhofer.de/example/Natural_Language_Processing\"\n",
    "# graph = Graph()\n",
    "# graph.parse(\"output/taxonomy_withOA.ttl\", format=\"ttl\")  # Load your RDF data\n",
    "\n",
    "# descendants_withOA = Evaluation.get_descendants(concept_uri, graph)\n",
    "# concepts_onto_withOA = Evaluation.clean_concept_names(descendants_withOA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4efb85",
   "metadata": {},
   "source": [
    "#### AutOnto w/o OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8a2500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "Total descendants found: 44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'http://fraunhofer.de/example/Amazon_Reviews',\n",
       " 'http://fraunhofer.de/example/Arabic_Language_Analysis',\n",
       " 'http://fraunhofer.de/example/Clinical_Text_Analysis',\n",
       " 'http://fraunhofer.de/example/Dialog_Systems',\n",
       " 'http://fraunhofer.de/example/Ensemble-Hybrid_Model',\n",
       " 'http://fraunhofer.de/example/Feature_Selection',\n",
       " 'http://fraunhofer.de/example/Fuzzy_Integral_Classifier_Fusion',\n",
       " 'http://fraunhofer.de/example/Fuzzy_Quantification_in_Hotel_Reviews',\n",
       " 'http://fraunhofer.de/example/Handwritten_Word_Recognition',\n",
       " 'http://fraunhofer.de/example/Image_Captioning',\n",
       " 'http://fraunhofer.de/example/Language_Acquisition',\n",
       " 'http://fraunhofer.de/example/Language_Analysis',\n",
       " 'http://fraunhofer.de/example/Lexicon_Development',\n",
       " 'http://fraunhofer.de/example/Linguistic_Analysis',\n",
       " 'http://fraunhofer.de/example/Logic_Rules_in_Sentiment_Classification',\n",
       " 'http://fraunhofer.de/example/Machine_Learning_Models_and_Approaches',\n",
       " 'http://fraunhofer.de/example/Machine_Translation',\n",
       " 'http://fraunhofer.de/example/Majority_Voting_Approach',\n",
       " 'http://fraunhofer.de/example/Named_Entity_Recognition',\n",
       " 'http://fraunhofer.de/example/Natural_Language_Understanding_and_Generation',\n",
       " 'http://fraunhofer.de/example/Natural_language_processing',\n",
       " 'http://fraunhofer.de/example/Neutrosophic_Sets',\n",
       " 'http://fraunhofer.de/example/News_Reviews_Sentiment_Lexicon',\n",
       " 'http://fraunhofer.de/example/Online_Pharmacy_Reviews',\n",
       " 'http://fraunhofer.de/example/Online_Reviews_Sentiment_Analysis',\n",
       " 'http://fraunhofer.de/example/Parsing_Strategies',\n",
       " 'http://fraunhofer.de/example/Question_Answering',\n",
       " 'http://fraunhofer.de/example/Semantic_Ontology',\n",
       " 'http://fraunhofer.de/example/Semantically_Enriched_Information',\n",
       " 'http://fraunhofer.de/example/Sentiment_Analysis',\n",
       " 'http://fraunhofer.de/example/Sign_Language_Analysis',\n",
       " 'http://fraunhofer.de/example/Specialized_Text_and_Speech_Processing',\n",
       " 'http://fraunhofer.de/example/Speech_Emotion_Recognition',\n",
       " 'http://fraunhofer.de/example/Speech_Recognition',\n",
       " 'http://fraunhofer.de/example/Students_Feedback_Analysis',\n",
       " 'http://fraunhofer.de/example/Text_Analysis',\n",
       " 'http://fraunhofer.de/example/Text_Analysis_and_Classification',\n",
       " 'http://fraunhofer.de/example/Text_Classification',\n",
       " 'http://fraunhofer.de/example/Text_Similarity_Studies',\n",
       " 'http://fraunhofer.de/example/Text_Summarization',\n",
       " 'http://fraunhofer.de/example/Tourist_Comment_Classification',\n",
       " 'http://fraunhofer.de/example/Twitter_Sentiment_Analysis',\n",
       " 'http://fraunhofer.de/example/Twitter_Sentiments_Analysis',\n",
       " 'http://fraunhofer.de/example/Word_Embeddings'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_uri = \"http://fraunhofer.de/example/Natural_language_processing\"\n",
    "file_path = \"output/taxonomy.ttl\"\n",
    "\n",
    "graph = Graph()\n",
    "graph.parse(\"output/taxonomy.ttl\", format=\"ttl\") \n",
    "print(len(graph)) # Load your RDF data\n",
    "\n",
    "descendants_withoutOA = Evaluation.get_descendants(concept_uri, graph)\n",
    "descendants_withoutOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e49d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts in OntoNLP with OA:  44\n"
     ]
    }
   ],
   "source": [
    "concepts_onto__withoutOA = Evaluation.clean_concept_names(descendants_withoutOA)\n",
    "print(\"Number of concepts in OntoNLP with OA: \", len(concepts_onto__withoutOA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f79cf0",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ff014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalinst = Evaluation()\n",
    "\n",
    "cso_list_processed = evalinst.preprocess_list(final_topics)\n",
    "# concepts_onto_withOA_processed = evalinst.preprocess_list(concepts_onto_withOA)\n",
    "concepts_onto_withoutOA_processed = evalinst.preprocess_list(concepts_onto__withoutOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e4e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained SentenceTransformer model\n",
    "whaleloops_model = SentenceTransformer(\"whaleloops/phrase-bert\")\n",
    "\n",
    "# Calculate metrics for preprocessed_list1\n",
    "phrase_embeddings1 = whaleloops_model.encode(cso_list_processed)\n",
    "reference_embedding = whaleloops_model.encode('natural-language-processing')\n",
    "metrics1 = Evaluation.calculate_metrics(phrase_embeddings1, reference_embedding)\n",
    "\n",
    "# # Calculate metrics for preprocessed_list2\n",
    "# phrase_embeddings2 = whaleloops_model.encode(concepts_onto_withOA_processed)\n",
    "# metrics2 = Evaluation.calculate_metrics(phrase_embeddings2, reference_embedding)\n",
    "\n",
    "# Calculate metrics for preprocessed_list2\n",
    "phrase_embeddings3 = whaleloops_model.encode(concepts_onto_withoutOA_processed)\n",
    "metrics3 = Evaluation.calculate_metrics(phrase_embeddings3, reference_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b53c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries to store the metrics\n",
    "data = [\n",
    "    {\n",
    "        \"List\": \"CSO\",\n",
    "        \"Number of Terms\": len(cso_list_processed),\n",
    "        **metrics1\n",
    "    },\n",
    "#     {\n",
    "#         \"List\": \"AutOnto with OA concepts\",\n",
    "#         \"Number of Terms\": len(concepts_onto_withOA_processed),\n",
    "#         **metrics2\n",
    "#     },\n",
    "        {\n",
    "        \"List\": \"AutOnto without OA concepts\",\n",
    "        \"Number of Terms\": len(concepts_onto_withoutOA_processed),\n",
    "        **metrics3\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "comparison = pd.DataFrame(data)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "comparison.to_csv(\"output/metrics_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29de65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
